#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os, shutil, hashlib
from tempfile import mkdtemp
from subprocess import check_call
import dicom
from soma import argparse
from soma import aims

class DicomAggregator( object ):
    def __init__( self ):
        self._dicom_sources = set()

    def add_dicom_sources( self, sources ):
        for source in sources:
            self._dicom_sources.add( source )

    def aggregate( self ):
        self._aggregate_sources = {}
        serie_sop_uids = {}
        for source in self._dicom_sources:
            filelist = []
            if os.path.isdir( source ):
                for root, dirs, files in os.walk( source ):
                    for name in files:
                        filelist.append( os.path.join( root, name ) )
            else:
                filelist = [ source ]
            for f in filelist:
                try:
                    ds = dicom.read_file( f )
                except:
                    continue
                serie_uid = ds.SeriesInstanceUID
                if not self._aggregate_sources.has_key( serie_uid ):
                    self._aggregate_sources[ serie_uid ] = []
                    serie_sop_uids[ serie_uid ] = []

                sop_uid = ds.SOPInstanceUID
                if not sop_uid in serie_sop_uids[ serie_uid ]:
                    serie_sop_uids[ serie_uid ].append( sop_uid )
                    self._aggregate_sources[ serie_uid ].append( f )

if __name__ == '__main__':
    parser = argparse.ArgumentParser( description =
'''
Convert input DICOM files into NIfTI files
''' )

    parser.add_argument( '-i', '--input',  nargs='+', help='input DICOM files/directories')
    parser.add_argument( '-o', '--output', help='output directory' )
    parser.add_argument( '-r', '--rescale', action="store_true", default=False, help='apply rescale slope and intercept to data' )

    args = parser.parse_args()

    if args.input is None or \
       args.output is None:
        parser.parse_args( [ '-h' ] )

    # Aggregate input files
    aggregator = DicomAggregator()
    aggregator.add_dicom_sources( args.input )
    aggregator.aggregate()

    # Browse aggregated DICOM series
    for serie in aggregator._aggregate_sources.values():
        uuid = None
        filesbytime = {}
        # Sort 4D DICOM files by time
        for f in serie:
            ds = dicom.read_file( f )

            try:
                modality = ds.Modality
            except:
                modality = ''

            if uuid == None and "FrameofReferenceUID" in ds:
                uuid = hashlib.md5( ds.FrameofReferenceUID ).hexdigest()
            time = -1
            
            # Check if the current file must be sorted by time
            if "FrameReferenceTime" in ds:
                try:
                    number_of_slices = ds[ 0x0054,0x0101 ].value
                    if number_of_slices > 1 and \
                       ds[ 0x0054,0x0081 ].value != len( serie ):
                        time = ds.FrameReferenceTime
                except:
                    time = -1
            if not filesbytime.has_key( time ):
                filesbytime[ time ] = []
            filesbytime[ time ].append( f )

        tmpdirs = []
        mcverter_options = [ '-f', 'nifti', '--nii', '-d' ]
        if args.rescale == True:
            mcverter_options.append( '-r' )
        # Convert each file group
        for t in sorted( filesbytime.keys() ):
            tmpdir = mkdtemp()
            tmpdirs.append( tmpdir )
            check_call( [ 'mcverter_x64', '-o', tmpdir ] + mcverter_options + filesbytime[ t ] )

        try:
            outfile =  os.path.join( args.output, \
                                         ds.PatientsName + '-' + ds.SeriesDate + '-' + \
                                         modality + '-' + \
                                         ds.SeriesDescription.replace( ' ', '_' ) + '-' + \
                                         ds.InstitutionName.replace( ' ', '_' ) + '.nii' )
        except:
            outfile = None

        # Merge the 4D series (if necessary) and move the convert files to the output directory
        if len( filesbytime ) > 1:
            convfiles = []
            for d in tmpdirs:
                convfiles.append( os.path.join( d, os.listdir( d )[0] ) )
            if outfile == None:
                outfile = os.path.join( args.output, os.path.basename( convfiles[0] ) )
            check_call( [ 'AimsTCat',
                          '-o',  outfile,
                          '-i' ] + convfiles )
        else:
            for f in os.listdir(tmpdir):
                if outfile == None:
                    outfile = os.path.join( args.output, f )
                shutil.move(os.path.join(tmpdir, f), outfile )

        # Clean temporary directories
        for d in tmpdirs:
            shutil.rmtree( d )

        # Add "referentials" to the minf file
        minf = os.path.join( outfile + '.minf' )
        uuid = '-'.join( [ uuid[ 0:8 ], uuid[ 8:12 ], uuid[ 12:16 ], uuid[ 16:20 ], uuid[ 20:32 ] ] )
        header = aims.read(outfile).header()
        fd = open( minf, 'w' )
        newattributes = { 'referentials': [ uuid ] }
        header.update( newattributes )
        print >> fd, "attributes = ", header
        fd.close()
