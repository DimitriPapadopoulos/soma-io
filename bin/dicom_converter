#!/usr/bin/env python
# -*- coding: utf-8 -*-
#  This software and supporting documentation are distributed by
#      Institut Federatif de Recherche 49
#      CEA/NeuroSpin, Batiment 145,
#      91191 Gif-sur-Yvette cedex
#      France
#
# This software is governed by the CeCILL license version 2 under
# French law and abiding by the rules of distribution of free software.
# You can  use, modify and/or redistribute the software under the 
# terms of the CeCILL license version 2 as circulated by CEA, CNRS
# and INRIA at the following URL "http://www.cecill.info". 
#
# As a counterpart to the access to the source code and  rights to copy,
# modify and redistribute granted by the license, users are provided only
# with a limited warranty  and the software's author,  the holder of the
# economic rights,  and the successive licensors  have only  limited
# liability.
#
# In this respect, the user's attention is drawn to the risks associated
# with loading,  using,  modifying and/or developing or reproducing the
# software by the user in light of its specific status of free software,
# that may mean  that it is complicated to manipulate,  and  that  also
# therefore means  that it is reserved for developers  and  experienced
# professionals having in-depth computer knowledge. Users are therefore
# encouraged to load and test the software's suitability as regards their
# requirements in conditions enabling the security of their systems and/or 
# data to be ensured and,  more generally, to use and operate it in the 
# same conditions as regards security.
#
# The fact that you are presently reading this means that you have had
# knowledge of the CeCILL license version 2 and that you accept its terms.

import os, shutil, hashlib, string, glob
import platform
from tempfile import mkdtemp, mkstemp
from subprocess import check_call
import dicom
import numpy as np
import soma
from soma.path import split_path
from soma.path import which
from soma import argparse, aims
from soma.dicom import aggregator
import subprocess
from soma.minf.api import readMinf

def get_mcverter():
    mcverter_exist_dic = { 'mcverter' : False, 'mcverter_x64' : False }

    for dir in os.environ.get( "PATH", "" ).split( os.pathsep ):
        for mcverter in mcverter_exist_dic.keys():
            if not mcverter_exist_dic[ mcverter ] and \
               os.path.exists( os.path.join( dir, mcverter ) ):
                mcverter_exist_dic[ mcverter ] = True

    processortype = platform.architecture()[0]
    if processortype == '64bit' and \
        mcverter_exist_dic[ 'mcverter_x64' ]:
        return 'mcverter_x64'
    elif mcverter_exist_dic[ 'mcverter' ]:
        return 'mcverter'

    return ''

def make_valid_filename( filename ):
    valid_chars = "-_.%s%s" % (string.ascii_letters, string.digits)
    return ''.join( c for c in filename.replace( ' ', '_' ) if c in valid_chars )

def findSharedFile( filename ):

    for dir in sorted( glob.glob( os.path.join( *(
                split_path( soma.__file__ )[:-3] + [ 'share', 'soma-*' ]) ) ) ):
        if os.path.exists( dir ):
            filepath = os.path.join( dir, filename )
            if os.path.exists( filepath ):
                return filepath

def get_start_and_duration_times( serie ):
    stdt = {}
    for f in serie:
        ds = dicom.read_file( f )
        try:
            if ds.Modality != 'PT':
                return None

            acq_time = ds.AcquisitionTime
            if not stdt.has_key( acq_time ):
                stdt.update( { acq_time : ds.ActualFrameDuration } )
        except:
            pass

    if len( stdt ) == 0:
        return None

    def conv_acqtime_to_msec( acq_time ):
        if len( acq_time ) < 6:
            return None
        msec = int( acq_time[:2] ) * 3600 + \
               int( acq_time[2:4] )*60 + \
               int( acq_time[4:6] )
        msec *= 1000
        if len( acq_time ) > 6:
            msec += int( acq_time[7:] ) / 1000
        return msec

    first_time = conv_acqtime_to_msec( min(stdt) )
    start_times = []
    duration_times = []
    for s, d in sorted( stdt.iteritems() ):
        start_times.append( conv_acqtime_to_msec( s ) - first_time )
        duration_times.append( int( d ) )

    return { 'start_time' : start_times, 'duration_time' : duration_times }

def check_transfer_syntax_uid(dicomFile):
    ds = dicom.read_file(dicomFile)
    if not ds.is_big_endian:
        return
    check_call([which("dcmconv"), "+te", dicomFile, dicomFile])

def check_jpeg(dicomFile):
    ds = dicom.read_file(dicomFile)
    if not "JPEG" in ds.file_meta.TransferSyntaxUID.name:
        return
    check_call([which("dcmdjpeg"), dicomFile, dicomFile])

def convert_to_nifti( serie, mergeDynSeries = True ):
    modality = ""
    uuid = None
    series_instance_uid = None
    filesbytime = {}
    indexesbytime = {}
    rescaleparamsbytime = {}
    tempfiles = []

    # Sort 4D DICOM files by time
    for f in serie:
        tempfile = mkstemp()[1]
        tempfiles.append( tempfile )

        shutil.copy(f, tempfile)
        os.chmod(tempfile, 0777)
        
        try:
            check_transfer_syntax_uid(tempfile)
            check_jpeg(tempfile)
        except OSError:
            print "The DICOM converter needs DCMTK binaries to convert", f
        
        ds = dicom.read_file(tempfile)

        if modality == "":
            try:
                modality = ds.Modality
            except:
                pass

        if series_instance_uid == None:
            try:
                series_instance_uid = ds.SeriesInstanceUID
            except:
                pass

        if uuid == None and "FrameofReferenceUID" in ds:
            uuid = hashlib.md5( ds.FrameofReferenceUID ).hexdigest()

        time = -1

        # Check if the current file must be sorted by time
        if "FrameReferenceTime" in ds:
            try:
                number_of_time_slices = ds[ 0x0054,0x0101 ].value
                if number_of_time_slices > 1 and \
                   ds[ 0x0054,0x0081 ].value != len( serie ):
                    time = ds.FrameReferenceTime
            except:
                time = -1
        if not filesbytime.has_key( time ):
            filesbytime[ time ] = []
            indexesbytime[ time ] = []
            rescaleparamsbytime[ time ] = []

        indexesbytime[time].append(ds.ImagePositionPatient[2])
        
        slope = 1
        inter = 0
        scale_factor = 1
        try:
            slope = ds.RescaleSlope
            inter = ds.RescaleIntercept
            if modality == 'PT' and \
               ds.Units == 'CNTS' and \
               ds.Manufacturer == 'Philips Medical Systems':
                if args.suv:
                    scale_factor = ds[ 0x7053,0x1000 ].value
                else:
                    scale_factor = ds[ 0x7053,0x1009 ].value
        except:
            pass

        rescaleparamsbytime[ time ].append( { 'RescaleSlope' : float( slope ), \
                                              'RescaleIntercept' : float( inter ), \
                                              'ScaleFactor' : float( scale_factor ) } )

        # Reset rescale parameters to be sure there will be
        # no rescale done by the NIfTI converter
        try:
            ds.RescaleSlope = 1
            ds.RescaleIntercept = 0
            ds[ 0x7053,0x1000 ].value = "1"
            ds[ 0x7053,0x1009 ].value = "1"
        except:
            pass

        ds.save_as( tempfile )

        filesbytime[ time ].append( tempfile )

    tmpdirsByTime = {}
    mcverter_options = [ '-f', 'nifti', '--nii' ]

    # Convert each file group
    for t in sorted( filesbytime.keys() ):
        # Reorder files by image index
        sorted_indexes = np.argsort( indexesbytime[t])[::-1]
        filesbytime[ t ] = list(np.take( filesbytime[ t ], sorted_indexes ))
        rescaleparamsbytime[ t ] = list(np.take( rescaleparamsbytime[ t ], sorted_indexes ))

        tmpdir = mkdtemp()
        tmpdirsByTime.update({t: tmpdir })
        check_call( [ get_mcverter(), '-o', tmpdir ] + mcverter_options + filesbytime[ t ] )
        try:
            for unneededFile in glob.glob(os.path.join(tmpdir, "*_info.txt")):
                os.remove(unneededFile)
        except:
            pass

    try:
        outfile = os.path.join( args.output, \
                                     make_valid_filename( \
                                        ds.PatientsName + '-' + ds.SeriesDate + '-' + \
                                        modality + '-' + \
                                        ds.SeriesDescription + '-' + \
                                        ds.InstitutionName + '.nii' ) )
    except:
        outfile = None

    # Merge the 4D series (if necessary) and move the convert files to the output directory
    outfilesByTime={}
    if len( filesbytime ) > 1:
        convfilesByTime = {}
        for t, d in tmpdirsByTime.items():
            convfilesByTime.update({t: os.path.join( d, os.listdir( d )[0] ) })

        if outfile == None:
          outfile = os.path.join(args.output, os.path.basename(convfilesByTime[sorted(convfilesByTime.keys())[0]]))

        if(mergeDynSeries):
          check_call( [ 'AimsTCat',
                      '-o',  outfile,
                      '-i' ] + convfilesByTime.values() )
          outfilesByTime.update({-1:[outfile]})
        else:
          tIdx = 0
          for t in sorted(convfilesByTime.keys()):
            f = convfilesByTime[t]
            outf = outfile+'_t'+str(tIdx)+'.nii'
            outfilesByTime.update({t:[outf]})
            shutil.move(f, outf )
            tIdx = tIdx+1

    else:
        if outfile is not None:
            if os.path.exists(outfile):
                os.remove(outfile)
            if os.path.exists(outfile + '.minf'):
                os.remove(outfile + '.minf')
        outfiles = []
        for f in os.listdir(tmpdir):
            if outfile == None:
                outfile = os.path.join( args.output, f )
            shutil.move(os.path.join(tmpdir, f), outfile )
            outfiles.append(outfile)
        outfilesByTime.update({-1 : outfiles})

    # Clean temporary directories and files
    for d in tmpdirsByTime.values():
        shutil.rmtree( d )
    for f in tempfiles:
        os.remove( f )

    if uuid != None:
        uuid = '-'.join([uuid[0:8], uuid[8:12], uuid[12:16], uuid[16:20], uuid[20:32]])

    # Apply pixel value rescale parameters
    for fileTime, outfiles in outfilesByTime.items():
      for outfile in outfiles:
        aims_file = aims.read( outfile )
        aims_conv = aims.Converter( intype=aims_file, outtype='Volume_FLOAT' )
        aims_float_file = aims_conv( aims_file )
        data_arr = np.array( aims_float_file, copy=False )

        if(mergeDynSeries):
          timecpt = 0
          for t in sorted( filesbytime.keys() ):
              for i in range( len( rescaleparamsbytime[t] ) ):
                  data_arr[:,:,i,timecpt] *= rescaleparamsbytime[t][i]['RescaleSlope']
                  data_arr[:,:,i,timecpt] += rescaleparamsbytime[t][i]['RescaleIntercept']
                  data_arr[:,:,i,timecpt] *= rescaleparamsbytime[t][i]['ScaleFactor']
              timecpt += 1
        else:
          for i in range( len( rescaleparamsbytime[fileTime] ) ):
            data_arr[:,:,i] *= rescaleparamsbytime[fileTime][i]['RescaleSlope']
            data_arr[:,:,i] += rescaleparamsbytime[fileTime][i]['RescaleIntercept']
            data_arr[:,:,i] *= rescaleparamsbytime[fileTime][i]['ScaleFactor']

        aims.write( aims_float_file, outfile )

        # Add "referentials" to the minf file
        minf = os.path.join( outfile + '.minf' )
        header = aims.read(outfile).header()
        fd = open( minf, 'w' )
        if uuid != None:
            newattributes = { 'referentials': [ uuid ], \
                              'modality': modality, \
                              'series_instance_uid': series_instance_uid }
        else:
            newattributes = { 'modality': modality, \
                              'series_instance_uid': series_instance_uid }

        if modality == 'PT':
            stdt = get_start_and_duration_times( serie )
            if stdt != None:
                newattributes.update( stdt )

        header.update( newattributes )
        print >> fd, "attributes = ", header
        fd.close()

    add_version_to_minf(minf, get_mcverter())

def convert_to_nifti_MR( serie ):

  uuid = None
  series_instance_uid = None

  ds = dicom.read_file( serie[ 0 ] )

  dcm2niiOptions = [ '-b', findSharedFile( 'dcm2nii_DV.ini' ) ]

  tmpdir = mkdtemp()
  check_call( [ 'dcm2nii' ] + dcm2niiOptions + \
              [ '-o', tmpdir, os.path.dirname( serie[ 0 ] ) ] )

  tags = ((0x0010, 0x0010), (0x0008, 0x0021),
          (0x0008, 0x0060), (0x0008, 0x103e),
          (0x0008, 0x0080))
  filename = ''
  for tag in tags:
      try:
          filename += ds[tag].value + '-'
      except:
          pass
  try:
      outfile = os.path.join(args.output, \
                             make_valid_filename(filename[:-1]))
  except:
      outfile = None

  outfiles = []

  # rename and copy nifti files
  # NB : keep extension in case of bvec/bval (DTI images)
  for f in os.listdir(tmpdir):

    extension = '.' + f.split( '.' )[ -1 ]
    if outfile == None:

      outfile = os.path.join( args.output, f )

    if os.path.exists( outfile + extension ):

      outfile = outfile + '_1'

    shutil.move(os.path.join(tmpdir, f), outfile + extension )
    if extension == '.nii':

      outfiles.append(outfile)

  # disapply rescaleSlope for Philips data
  if ds.Manufacturer == 'Philips Medical Systems':

    rescaleSlope = 1.
    rescaleIntercept = 0
    try:
      rescaleSlope = ds.RescaleSlope
      rescaleIntercept = ds.RescaleIntercept
    except:
      try:
        rescaleSlope = \
                ds[0x5200,0x9230][ 0 ][0x0028,0x9145][ 0 ][0x0028,0x1053].value
        rescaleIntercept = \
                ds[0x5200,0x9230][ 0 ][0x0028,0x9145][ 0 ][0x0028,0x1052].value
      except:
        pass

    for outfile in outfiles:

      niftiFileImage = aims.read( outfile )
      niftiFileArray = np.array( niftiFileImage, copy=False )
      niftiFileArray = ( niftiFileArray - rescaleIntercept ) / rescaleSlope
      niftiFileArray = np.round( niftiFileArray )
      niftiFileArray = np.int16( niftiFileArray )
      niftiFileArray = np.array( niftiFileArray, order='F' )
      newNiftiFileImage = aims.Volume( niftiFileArray )
      initialVoxelSize = niftiFileImage.header()[ 'voxel_size' ]
      newNiftiFileImage.header()[ 'voxel_size' ] = initialVoxelSize
      aims.write( newNiftiFileImage, outfile )

  shutil.rmtree( tmpdir )

  # add seriesInstanceUID and referentials to .minf
  if series_instance_uid == None:
    try:
      series_instance_uid = ds.SeriesInstanceUID
    except:
      pass

  if uuid == None and "FrameofReferenceUID" in ds:
    uuid = hashlib.md5( ds.FrameofReferenceUID ).hexdigest()

  minf = os.path.join( outfile + '.nii.minf' )
  header = aims.read(outfile).header()
  fd = open( minf, 'w' )
  if uuid != None:

      newattributes = { 'referentials': [ uuid ], \
                        'series_instance_uid': series_instance_uid }

  header.update( newattributes )
  print >> fd, "attributes = ", header
  fd.close()

def convert_to_nifti_NM( serie ):
    tmpDir = mkdtemp()
    shutil.copy(serie[0], tmpDir)
    tempFile = os.path.join(tmpDir, os.path.basename(serie[0]))
    os.chmod(tempFile, 0777)
    
    try:
        check_transfer_syntax_uid(tempFile)
        check_jpeg(tempFile)
    except OSError:
        print "The DICOM converter needs DCMTK binaries to convert", f
    
    ds = dicom.read_file(tempFile)
    tags = ((0x0010, 0x0010), (0x0008, 0x0020),
            (0x0008, 0x0060), (0x0008, 0x103e),
            (0x0008, 0x0080))
    filename = ''
    for tag in tags:
        try:
            filename += ds[tag].value + '-'
        except:
            pass
    try:
        outfile = os.path.join( args.output, \
                                make_valid_filename(filename[:-1] + '.nii'))
    except:
        outfile = None
#    try:
#        outfile = os.path.join( args.output, \
#                                make_valid_filename( \
#                                  ds.PatientsName + '-' + ds.StudyDate + '-' + \
#                                  ds.Modality + '-' + \
#                                  ds.SeriesDescription + '-' + \
#                                  ds.InstitutionName ) + ".nii" )
#        
#    except:
#        outfile = None

    check_call( [ 'AimsFileConvert', '-i', tempFile, '-o', outfile ] )
    rescale_image_according_to_minf(outfile)
#    try:
#        if ds[0x0008,0x0070].value == "SIEMENS NM" and \
#           ds[0x0008,0x1090].value == "Encore2":
#            check_call( [ 'AimsFlip', '-i', outfile, '-o', outfile, '-m', 'ZZ' ] )
#    except:
#        pass

    uuid = None
    if "FrameofReferenceUID" in ds:
        uuid = hashlib.md5(ds.FrameofReferenceUID).hexdigest()
        uuid = '-'.join([uuid[0:8], uuid[8:12], uuid[12:16], uuid[16:20], uuid[20:32]])
    header = aims.read(outfile).header()
    minf = os.path.join(outfile + '.minf')
    fd = open(minf, 'w')
    if uuid != None:
        newattributes = {'referentials': [uuid],
                         'modality': ds.Modality,
                         'series_instance_uid': ds.SeriesInstanceUID}
        
#        try:
#            detectorInf = ds.DetectorInformations
#            if len(detectorInf) == 1:
#                imagePosition = detectorInf[0].ImagePositionPatient
#                transformation = header['transformations'][0]
#                transformation[3] = -imagePosition[0]
#                transformation[7] = -imagePosition[1]
#                transformation[11] = ds.SpacingBetweenSlices*ds.NumberofSlices + imagePosition[2]
#                newattributes.update({'transformations': [transformations]})
#        except:
#            pass
    else:
        newattributes = {'modality': ds.Modality,
                         'series_instance_uid': ds.SeriesInstanceUID}
    header.update(newattributes)
    print >> fd, "attributes = ", header
    fd.close()

    add_version_to_minf(minf, "AimsFileConvert")

def rescale_image_according_to_minf(niftiFile):
    img = aims.read(niftiFile)
    if img.header().has_key('rescale_applied') and img.header()['rescale_applied'] == 1:
        return
    try:
        slope = img.header()['rescale_slope'][0]
        inter = img.header()['rescale_intercept'][0]
    except:
        return
    floatImg = aims.Converter(intype=img, outtype='Volume_FLOAT')(img)
    arr = np.array(floatImg, copy=False)
    arr *= slope
    arr += inter
    img.header()['rescale_applied'] = 1
    aims.write(floatImg, niftiFile)

def add_version_to_minf(minf, converter):
    cmd = [converter, '--version']
    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    version, errors = p.communicate()
    newAttr = {'converter':
                     {'name': converter,
                      'version': version}
                     }
    oMinf = readMinf(minf)[0]
    oMinf.update(newAttr)
    fd = open(minf, 'w')
    print >> fd, "attributes = ", oMinf
    fd.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser( description =
'''
Convert input DICOM files into NIfTI files
''' )

    parser.add_argument( '-i', '--input',  nargs='+', help='input DICOM files/directories')
    parser.add_argument( '-o', '--output', help='output directory' )
    parser.add_argument( '-s', '--split4DSeries', help='do NOT merge the 4D series', action="store_false", dest="merge4DSeries")
    parser.add_argument( '-m', '--merge4DSeries', help='Merge the 4D series [default]', action="store_true", dest="merge4DSeries", default = True)
    parser.add_argument( '--suv', help='Apply SUV factor (for now, only for Philips manufacturer)', action="store_true", dest="suv", default = False)

    args = parser.parse_args()

    if args.input is None or \
       args.output is None:
        parser.parse_args( [ '-h' ] )

    # Aggregate input files
    aggregator = aggregator.DicomAggregator()
    aggregator.add_dicom_sources( args.input )
    aggregator.aggregate()

    # Browse aggregated DICOM series
    for serie in aggregator._aggregate_sources.values():

      ds = dicom.read_file( serie[ 0 ] )
      try:
        modality = ds.Modality
      except:
        modality = ""

      # Choose method according to modality
      if modality == 'MR':
          convert_to_nifti_MR( serie )
      elif modality == "NM" and len( serie ) == 1:
          convert_to_nifti_NM( serie )
      else:
          if not get_mcverter():
              print 'mcverter was not found on your system. It is mandatory to convert your DICOM files.'
              exit(0)
          convert_to_nifti( serie, args.merge4DSeries )
