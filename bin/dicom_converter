#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os, shutil, hashlib, string
import platform
from tempfile import mkdtemp, mkstemp
from subprocess import check_call
import dicom
import numpy as np
from soma import argparse, aims, dicomaggregator

def get_mcverter():
    mcverter_exist_dic = { 'mcverter' : False, 'mcverter_x64' : False }
    
    for dir in os.environ.get( "PATH", "" ).split( os.pathsep ):
        for mcverter in mcverter_exist_dic.keys():
            if not mcverter_exist_dic[ mcverter ] and \
               os.path.exists( os.path.join( dir, mcverter ) ):
                mcverter_exist_dic[ mcverter ] = True

    processortype = platform.architecture()[0]
    if processortype == '64bit' and \
        mcverter_exist_dic[ 'mcverter_x64' ]:
        return 'mcverter_x64'
    elif mcverter_exist_dic[ 'mcverter' ]:
        return 'mcverter'
        
    return ''

def get_start_and_duration_times( serie ):
    stdt = {}
    for f in serie:
        ds = dicom.read_file( f )
        try:
            if ds.Modality != 'PT':
                return None
            
            acq_time = ds.AcquisitionTime
            if not stdt.has_key( acq_time ):
                stdt.update( { acq_time : ds.ActualFrameDuration } )
        except:
            pass
    
    if len( stdt ) == 0:
        return None
    
    def conv_acqtime_to_msec( acq_time ):
        if len( acq_time ) < 6:
            return None
        msec = int( acq_time[:2] ) * 3600 + \
               int( acq_time[2:4] )*60 + \
               int( acq_time[4:6] )
        msec *= 1000
        if len( acq_time ) > 6:
            msec += int( acq_time[7:] ) / 1000
        return msec
    
    first_time = conv_acqtime_to_msec( min(stdt) )
    start_times = []
    duration_times = []
    for s, d in sorted( stdt.iteritems() ):
        start_times.append( conv_acqtime_to_msec( s ) - first_time )
        duration_times.append( int( d ) )

    return { 'start_time' : start_times, 'duration_time' : duration_times }

def convert_to_nifti( serie, mergeDynSeries = True ):
    
    def make_valid_filename( filename ):
        valid_chars = "-_.%s%s" % (string.ascii_letters, string.digits)
        return ''.join( c for c in filename.replace( ' ', '_' ) if c in valid_chars )
    
    modality = ""
    uuid = None
    series_instance_uid = None
    filesbytime = {}
    indexesbytime = {}
    rescaleparamsbytime = {}
    tempfiles = []

    # Sort 4D DICOM files by time
    for f in serie:
        tempfile = mkstemp()[1]
        tempfiles.append( tempfile )

        ds = dicom.read_file( f )

        if modality == "":
            try:
                modality = ds.Modality
            except:
                pass

        if series_instance_uid == None:
            try:
                series_instance_uid = ds.SeriesInstanceUID
            except:
                pass

        if uuid == None and "FrameofReferenceUID" in ds:
            uuid = hashlib.md5( ds.FrameofReferenceUID ).hexdigest()
        time = -1
        
        # Check if the current file must be sorted by time
        if "FrameReferenceTime" in ds:
            try:
                number_of_time_slices = ds[ 0x0054,0x0101 ].value
                if number_of_time_slices > 1 and \
                   ds[ 0x0054,0x0081 ].value != len( serie ):
                    time = ds.FrameReferenceTime
            except:
                time = -1
        if not filesbytime.has_key( time ):
            filesbytime[ time ] = []
            indexesbytime[ time ] = []
            rescaleparamsbytime[ time ] = []

        indexesbytime[ time ].append( ds.InstanceNumber )
        
        slope = 1
        inter = 0
        scale_factor = 1
        try:
            slope = ds.RescaleSlope
            inter = ds.RescaleIntercept
            if modality == 'PT' and \
               ds.Units == 'CNTS' and \
               ds.Manufacturer == 'Philips Medical Systems':
                scale_factor = ds[ 0x7053,0x1009 ].value
        except:
            pass
        
        rescaleparamsbytime[ time ].append( { 'RescaleSlope' : slope, \
                                              'RescaleIntercept' : inter, \
                                              'ScaleFactor' : scale_factor } )
        
        # Reset rescale parameters to be sure there will be
        # no rescale done by the NIfTI converter
        try:
            ds.RescaleSlope = 1
            ds.RescaleIntercept = 0
            ds[ 0x7053,0x1009 ].value = 1
        except:
            pass
        
        ds.save_as( tempfile )
        
        filesbytime[ time ].append( tempfile )

    tmpdirsByTime = {}
    mcverter_options = [ '-f', 'nifti', '--nii' ]

    # Convert each file group
    for t in sorted( filesbytime.keys() ):
        # Reorder files by image index
        sorted_indexes = np.argsort( indexesbytime[ t ])
        filesbytime[ t ] = list(np.take( filesbytime[ t ], sorted_indexes ))
        rescaleparamsbytime[ t ] = list(np.take( rescaleparamsbytime[ t ], sorted_indexes ))

        tmpdir = mkdtemp()
        tmpdirsByTime.update({t: tmpdir })
        check_call( [ get_mcverter(), '-o', tmpdir ] + mcverter_options + filesbytime[ t ] )

    try:
        outfile = os.path.join( args.output, \
                                     make_valid_filename( \
                                        ds.PatientsName + '-' + ds.SeriesDate + '-' + \
                                        modality + '-' + \
                                        ds.SeriesDescription + '-' + \
                                        ds.InstitutionName + '.nii' ) )
    except:
        outfile = None

    # Merge the 4D series (if necessary) and move the convert files to the output directory
    outfilesByTime={}
    if len( filesbytime ) > 1:
        convfilesByTime = {}
        for t, d in tmpdirsByTime.items():
            convfilesByTime.update({t: os.path.join( d, os.listdir( d )[0] ) })        
        
        if outfile == None:
          outfile = os.path.join( args.output, os.path.basename( convfilesByTime[0] ) )          

        if(mergeDynSeries):
          check_call( [ 'AimsTCat',
                      '-o',  outfile,
                      '-i' ] + convfilesByTime.values() )
          outfilesByTime.update({-1:outfile})        
        else:
          tIdx = 0 
          for t in sorted(convfilesByTime.keys()):
            f = convfilesByTime[t]                    
            outf = outfile+'_t'+str(tIdx)+'.nii'
            outfilesByTime.update({t:outf})
            shutil.move(f, outf ) 
            tIdx = tIdx+1       
          
    else:
        outfiles = []
        for f in os.listdir(tmpdir):
            if outfile == None:
                outfile = os.path.join( args.output, f )
            shutil.move(os.path.join(tmpdir, f), outfile )
            outfiles.append(outfile)
        outfilesByTime.update({-1 : outfiles})

    # Clean temporary directories and files
    for d in tmpdirsByTime.values():
        shutil.rmtree( d )
    for f in tempfiles:
        os.remove( f )

    # Apply pixel value rescale parameters
    for fileTime, outfile in outfilesByTime.items():
      aims_file = aims.read( outfile )
      aims_conv = aims.Converter( intype=aims_file, outtype='Volume_FLOAT' )
      aims_float_file = aims_conv( aims_file )
      data_arr = np.array( aims_float_file, copy=False )
      
      if(mergeDynSeries):
        timecpt = 0
        for t in sorted( filesbytime.keys() ):
            for i in range( len( rescaleparamsbytime[t] ) ):
                data_arr[:,:,i,timecpt] *= rescaleparamsbytime[t][i]['RescaleSlope']
                data_arr[:,:,i,timecpt] += rescaleparamsbytime[t][i]['RescaleIntercept']
                data_arr[:,:,i,timecpt] *= rescaleparamsbytime[t][i]['ScaleFactor']
            timecpt += 1
      else:
        for i in range( len( rescaleparamsbytime[fileTime] ) ):
          data_arr[:,:,i] *= rescaleparamsbytime[fileTime][i]['RescaleSlope']
          data_arr[:,:,i] += rescaleparamsbytime[fileTime][i]['RescaleIntercept']
          data_arr[:,:,i] *= rescaleparamsbytime[fileTime][i]['ScaleFactor']
          
      aims.write( aims_float_file, outfile )
  
      # Add "referentials" to the minf file
      minf = os.path.join( outfile + '.minf' )
      if uuid != None:
          uuid = '-'.join( [ uuid[ 0:8 ], uuid[ 8:12 ], uuid[ 12:16 ], uuid[ 16:20 ], uuid[ 20:32 ] ] )
      header = aims.read(outfile).header()
      fd = open( minf, 'w' )
      if uuid != None:
          newattributes = { 'referentials': [ uuid ], \
                            'modality': modality, \
                            'series_instance_uid': series_instance_uid }
      else:
          newattributes = { 'modality': modality, \
                            'series_instance_uid': series_instance_uid }
      
      if modality == 'PT':
          stdt = get_start_and_duration_times( serie )
          if stdt != None:
              newattributes.update( stdt )
      
      header.update( newattributes )
      print >> fd, "attributes = ", header
      fd.close()


if __name__ == '__main__':
    
    if not get_mcverter():
        print 'mcverter was not found on your system. It is mandatory to convert your DICOM files.'
        exit(0)
    
    parser = argparse.ArgumentParser( description =
'''
Convert input DICOM files into NIfTI files
''' )

    parser.add_argument( '-i', '--input',  nargs='+', help='input DICOM files/directories')
    parser.add_argument( '-o', '--output', help='output directory' )
    parser.add_argument( '-s', '--split4DSeries', help='do NOT merge the 4D series', action="store_false", dest="merge4DSeries")
    parser.add_argument( '-m', '--merge4DSeries', help='Merge the 4D series [default]', action="store_true", dest="merge4DSeries", default = True)

    args = parser.parse_args()

    if args.input is None or \
       args.output is None:
        parser.parse_args( [ '-h' ] )

    # Aggregate input files
    aggregator = dicomaggregator.DicomAggregator()
    aggregator.add_dicom_sources( args.input )
    aggregator.aggregate()

    # Browse aggregated DICOM series
    for serie in aggregator._aggregate_sources.values():
      convert_to_nifti( serie, args.merge4DSeries )